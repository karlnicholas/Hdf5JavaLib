# Hdf5JavaLib: Read Capabilities (Beta)

Hdf5JavaLib is a pure Java library for reading HDF5 files, currently in beta. This guide helps new users experiment with reading datasets in the root group, using examples from the `org.hdf5javalib.examples.read` package. The library reads HDF5 files generated by the C++ HDF5 library, supporting compound datasets, multi-dimensional data, and various datatypes.

## Setup

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/karlnicholas/Hdf5JavaLib.git
   ```
2. **Build with Maven**:
   ```bash
   cd Hdf5JavaLib
   mvn install
   ```
3. **Requirements**:
   - Java 17+.
   - No external HDF5 dependencies.
4. **Example Files**:
   - All required `.h5` files (e.g., `compound_example.h5`, `scalar.h5`) are in `src/test/resources`.

## Read Capabilities

Hdf5JavaLib supports reading datasets in the root group (`/`), including:
- **Compound Datasets**: Structured data with fields like integers, strings, and floats (e.g., `CompoundData` with `recordId`, `fixedStr`).
- **Scalar Datasets**: Single values (e.g., fixed-point, floating-point, strings).
- **Vector Datasets**: 1D arrays (e.g., strings, integers).
- **Matrix Datasets**: 2D arrays (e.g., weather data).
- **Multi-Dimensional Datasets**: Tested with arrays up to 4D (e.g., Tic-Tac-Toe game state).
- **Variable-Length Datasets**: Arrays of varying sizes.
- **Datatypes**: Fixed-point (`BigInteger`, `BigDecimal`), floating-point (`Float`, `Double`), strings (ASCII, UTF-8), time, bitfields, compounds, opaque, references, enums, arrays.
- **Metadata**: Partial support for SNODs (symbol table nodes).

The library supports sequential and parallel streaming for efficient data processing.

## Usage

Use the `HdfFileReader` class (in `org.hdf5javalib.file`) to read HDF5 files. The `TypedDataSource` class provides typed data access (scalar, vector, matrix) and streaming, while `HdfDisplayUtils` simplifies data display. The `org.hdf5javalib.examples.read` package shows how to read different datasets.

### Example 1: Read a Compound Dataset

This example reads a compound dataset (`CompoundData`) from `compound_example.h5`, with fields like `recordId` (Long) and `fixedStr` (String), and maps it to a custom Java class.

```java
package org.hdf5javalib.examples.read;

import org.hdf5javalib.HdfFileReader;
import org.hdf5javalib.dataclass.HdfCompound;
import org.hdf5javalib.datasource.TypedDataSource;
import org.hdf5javalib.file.HdfDataSet;

import java.nio.channels.SeekableByteChannel;
import java.nio.file.Files;
import java.nio.file.Paths;
import java.nio.file.StandardOpenOption;

public class HdfCompoundRead {
    public static void main(String[] args) throws Exception {
        String filePath = HdfCompoundRead.class.getClassLoader().getResource("compound_example.h5").getPath();
        try (SeekableByteChannel channel = Files.newByteChannel(Paths.get(filePath), StandardOpenOption.READ)) {
            HdfFileReader reader = new HdfFileReader(channel).readFile();
            try (HdfDataSet dataSet = reader.getRootGroup().findDataset("CompoundData")) {
                new TypedDataSource<>(channel, reader, dataSet, HdfCompound.class)
                    .streamVector()
                    .limit(2)
                    .forEach(c -> System.out.println("Row: " + c.getMembers()));
            }
        }
    }
}
```

**Output** (example):
```
Row: [recordId=1000, fixedStr="Fixed0", varStr="Variable0", ...]
Row: [recordId=1001, fixedStr="Fixed1", varStr="Variable1", ...]
```

### Example 2: Read Scalar Datasets

This example reads scalar datasets from `twenty_datasets.h5`, displaying values as `Long`.

```java
package org.hdf5javalib.examples.read;

import org.hdf5javalib.HdfFileReader;
import org.hdf5javalib.file.HdfDataSet;
import org.hdf5javalib.utils.HdfDisplayUtils;

import java.nio.channels.SeekableByteChannel;
import java.nio.file.Files;
import java.nio.file.Paths;
import java.nio.file.StandardOpenOption;

public class HdfTwentyScalarRead {
    public static void main(String[] args) throws Exception {
        String filePath = HdfTwentyScalarRead.class.getClassLoader().getResource("twenty_datasets.h5").getPath();
        try (SeekableByteChannel channel = Files.newByteChannel(Paths.get(filePath), StandardOpenOption.READ)) {
            HdfFileReader reader = new HdfFileReader(channel).readFile();
            for (HdfDataSet dataSet : reader.getRootGroup().getDataSets()) {
                try (HdfDataSet ds = dataSet) {
                    HdfDisplayUtils.displayScalarData(channel, ds, Long.class, reader);
                }
            }
        }
    }
}
```

**Output** (example):
```
Dataset0: 123
Dataset1: 456
...
```

### Example 3: Read a String Vector

This example reads a vector of ASCII strings from `ascii_dataset.h5`.

```java
package org.hdf5javalib.examples.read;

import org.hdf5javalib.HdfFileReader;
import org.hdf5javalib.file.HdfDataSet;
import org.hdf5javalib.utils.HdfDisplayUtils;

import java.nio.channels.FileChannel;
import java.nio.file.Files;
import java.nio.file.Paths;

public class HdfStringRead {
    public static void main(String[] args) throws Exception {
        String filePath = HdfStringRead.class.getClassLoader().getResource("ascii_dataset.h5").getFile();
        try (FileChannel channel = (FileChannel) Files.newByteChannel(Paths.get(filePath))) {
            HdfFileReader reader = new HdfFileReader(channel).readFile();
            try (HdfDataSet dataSet = reader.getRootGroup().findDataset("strings")) {
                HdfDisplayUtils.displayVectorData(channel, dataSet, String.class, reader);
            }
        }
    }
}
```

**Output** (example):
```
["Hello", "World", "HDF5"]
```

## Running Examples

1. **Locate `.h5` Files**:
   - All example files (e.g., `compound_example.h5`, `scalar.h5`, `ascii_dataset.h5`) are in `src/test/resources`.
   - No additional downloads are needed.
2. **Compile and Run**:
   ```bash
   mvn test
   java -cp target/classes org.hdf5javalib.examples.read.HdfCompoundRead
   ```
3. **Tips**:
   - Use Java 17+.
   - On Windows, file paths may need adjustment (e.g., remove leading `/`).
   - Run `mvn test` to verify examples.

## Limitations

- **Beta Status**: Reads datasets in the root group only (`/`).
- **No Subgroups**: Groups beyond the root group are not supported.
- **No Compression or Chunking**: Cannot read compressed or chunked datasets.
- **Partial Metadata Support**: Reads SNODs but not attributes or advanced structures (e.g., fractal heaps).
- **Tested Scope**: Validated with C++ HDF5 files in `src/test/resources` (e.g., compound datasets, up to 4D arrays).

## Feedback

Help improve Hdf5JavaLib by reporting issues at [GitHub Issues](https://github.com/karlnicholas/Hdf5JavaLib/issues). Please include:
- Sample HDF5 files that fail to read.
- Expected outputs or error messages.
- Suggestions for new features (e.g., subgroup support, chunking).

Visit [www.hdf5javalib.org](https://www.hdf5javalib.org) for updates and resources.